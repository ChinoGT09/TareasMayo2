// Autor: Jflores
// Modificado para trabajar con todo el dataset IRIS
// marzo 2025

// Cargar el dataset IRIS completo (150 muestras)
iris_data = csvRead("iris.csv"); // Asumiendo un archivo CSV con los datos
// Estructura esperada: 5 columnas (4 características + 1 clase)

// Separar características (X) y etiquetas (Y)
X_raw = iris_data(:, 1:4);
Y_raw = iris_data(:, 5);

// Normalizar los datos (escalar características a [0,1])
X_min = min(X_raw, 'r');
X_max = max(X_raw, 'r');
X = (X_raw - repmat(X_min, size(X_raw,1),1)) ./ repmat(X_max-X_min, size(X_raw,1),1);

// Convertir etiquetas a codificación one-hot
Y = zeros(size(Y_raw,1), 3);
for i=1:size(Y_raw,1)
    if Y_raw(i) == 1 then
        Y(i,:) = [1,0,0];
    elseif Y_raw(i) == 2 then
        Y(i,:) = [0,1,0];
    else
        Y(i,:) = [0,0,1];
    end
end

// Dividir en conjuntos de entrenamiento (70%) y prueba (30%)
rand_indices = grand(1, "prm", 1:size(X,1));
train_size = round(0.7 * size(X,1));
X_train = X(rand_indices(1:train_size), :);
Y_train = Y(rand_indices(1:train_size), :);
X_test = X(rand_indices(train_size+1:$), :);
Y_test = Y(rand_indices(train_size+1:$), :);

// Parámetros de la red
n_entradas = 4;   // Número de entradas (4 características)
n_ocultas = 10;   // Neuronas en la capa oculta
n_salidas = 3;    // Neuronas en la capa de salida (3 clases)

// Función de activación sigmoide
function y = sigmoid(x)
    y = 1 ./ (1 + exp(-x));
endfunction

// Derivada de la sigmoide
function y = sigmoid_derivada(x)
    y = sigmoid(x) .* (1 - sigmoid(x));
endfunction

// Inicializar pesos y sesgos aleatoriamente
W1 = rand(n_entradas, n_ocultas, "normal") * 0.1;
b1 = zeros(1, n_ocultas);
W2 = rand(n_ocultas, n_salidas, "normal") * 0.1;
b2 = zeros(1, n_salidas);

// Hiperparámetros
tasa_aprendizaje = 0.1;
max_iter = 5000;
batch_size = 10; // Tamaño del mini-batch

// Entrenamiento con mini-batches
disp("Entrenamiento:");
for iter = 1:max_iter
    // Seleccionar mini-batch aleatorio
    batch_indices = grand(1, "prm", 1:size(X_train,1))(1:batch_size);
    X_batch = X_train(batch_indices, :);
    Y_batch = Y_train(batch_indices, :);
    
    // Propagación hacia adelante
    b1_expanded = repmat(b1, batch_size, 1);
    Z1 = X_batch * W1 + b1_expanded;
    A1 = sigmoid(Z1);
    
    b2_expanded = repmat(b2, batch_size, 1);
    Z2 = A1 * W2 + b2_expanded;
    A2 = sigmoid(Z2);
    
    // Cálculo del error
    error = Y_batch - A2;
    
    // Retropropagación
    dZ2 = error .* sigmoid_derivada(Z2);
    dW2 = A1' * dZ2 / batch_size;
    db2 = sum(dZ2, 1) / batch_size;
    
    dZ1 = (dZ2 * W2') .* sigmoid_derivada(Z1);
    dW1 = X_batch' * dZ1 / batch_size;
    db1 = sum(dZ1, 1) / batch_size;
    
    // Actualizar pesos y sesgos
    W2 = W2 + tasa_aprendizaje * dW2;
    b2 = b2 + tasa_aprendizaje * db2;
    W1 = W1 + tasa_aprendizaje * dW1;
    b1 = b1 + tasa_aprendizaje * db1;
    
    // Mostrar progreso cada 500 iteraciones
    if modulo(iter, 500) == 0
        // Calcular precisión en entrenamiento
        train_pred = sigmoid(sigmoid(X_train * W1 + repmat(b1, size(X_train,1),1)) * W2 + repmat(b2, size(X_train,1),1));
        train_acc = mean(round(train_pred) == Y_train) * 100;
        
        // Calcular precisión en prueba
        test_pred = sigmoid(sigmoid(X_test * W1 + repmat(b1, size(X_test,1),1)) * W2 + repmat(b2, size(X_test,1),1));
        test_acc = mean(round(test_pred) == Y_test) * 100;
        
        mprintf("Iteración %d - Precisión: Entrenamiento %.2f%%, Prueba %.2f%%\n", iter, train_acc, test_acc);
    end
end

// Evaluación final
Y_pred_train = round(sigmoid(sigmoid(X_train * W1 + repmat(b1, size(X_train,1),1)) * W2 + repmat(b2, size(X_train,1),1)));
Y_pred_test = round(sigmoid(sigmoid(X_test * W1 + repmat(b1, size(X_test,1),1)) * W2 + repmat(b2, size(X_test,1),1)));

// Calcular métricas
function [accuracy, confusion_matrix] = evaluate_performance(Y_true, Y_pred)
    accuracy = mean(Y_true == Y_pred) * 100;
    
    confusion_matrix = zeros(3,3);
    for i = 1:size(Y_true,1)
        true_class = find(Y_true(i,:) == 1);
        pred_class = find(Y_pred(i,:) == 1);
        confusion_matrix(true_class, pred_class) = confusion_matrix(true_class, pred_class) + 1;
    end
endfunction

[train_acc, train_cm] = evaluate_performance(Y_train, Y_pred_train);
[test_acc, test_cm] = evaluate_performance(Y_test, Y_pred_test);

// Mostrar resultados
disp(" ");
disp("RESULTADOS FINALES");
disp("----------------------------------");
disp("Precisión en entrenamiento: "+string(train_acc)+"%");
disp("Matriz de confusión (entrenamiento):");
disp(train_cm);

disp(" ");
disp("Precisión en prueba: "+string(test_acc)+"%");
disp("Matriz de confusión (prueba):");
disp(test_cm);

// Función para graficar fronteras de decisión (2D para visualización)
function plot_decision_boundaries(W1, b1, W2, b2, X, Y)
    // Seleccionar dos características para visualización (sepal length vs petal length)
    feat1 = 1; feat2 = 3;
    X_vis = X(:, [feat1, feat2]);
    
    // Crear grid para el gráfico
    x1 = linspace(min(X_vis(:,1)), max(X_vis(:,1)), 100);
    x2 = linspace(min(X_vis(:,2)), max(X_vis(:,2)), 100);
    [X1, X2] = meshgrid(x1, x2);
    Z = zeros(size(X1));
    
    // Calcular predicciones para cada punto del grid
    for i = 1:size(X1,1)
        for j = 1:size(X1,2)
            input = zeros(1,4);
            input(feat1) = X1(i,j);
            input(feat2) = X2(i,j);
            // Las otras características se mantienen en su media
            input(setdiff(1:4, [feat1, feat2])) = mean(X(:, setdiff(1:4, [feat1, feat2])));
            
            output = sigmoid(sigmoid(input * W1 + b1) * W2 + b2);
            [max_val, class] = max(output);
            Z(i,j) = class;
        end
    end
    
    // Graficar
    scf();
    f = gcf();
    f.figure_name = "Fronteras de Decisión";
    
    contourf(x1, x2, Z, [1 2 3], "jet");
    colorbar("vertical", 1:3, ["Setosa"; "Versicolor"; "Virginica"]);
    
    // Graficar puntos de datos reales
    classes = [find(Y(:,1)==1); find(Y(:,2)==1); find(Y(:,3)==1)];
    scatter(X_vis(classes(1:50),1), X_vis(classes(1:50),2), 'r', 'o', 'fill');
    scatter(X_vis(classes(51:100),1), X_vis(classes(51:100),2), 'g', 'o', 'fill');
    scatter(X_vis(classes(101:$),1), X_vis(classes(101:$),2), 'b', 'o', 'fill');
    
    xlabel("Longitud del sépalo (normalizada)");
    ylabel("Longitud del pétalo (normalizada)");
    title("Fronteras de Decisión de la Red Neuronal");
    legend(["Setosa"; "Versicolor"; "Virginica"]);
endfunction

// Graficar fronteras de decisión
plot_decision_boundaries(W1, b1, W2, b2, X, Y);